import urllib.parse
import ssl, socket    
from dateutil.parser import parse
import whois
from unshortenit import UnshortenIt
import Scan_site_by_SSH
from urllib.parse import urlparse

class ScanPhishing():

    def ScanCountry(url1): #1-1 차 테스트
        result_1st,result_name = Scan_site_by_SSH.AutoExtractor.scanSiteMain(url1)
        if result_1st ==1:
            print(result_name,"사칭 사이트")
            return result_name #사칭사이트
        else:
            return '사칭 리스트에 없음' #사칭 사이트    
    
    def having_IP_Address(url): #URL 내 IP 가 존재하는가?
        parse = urllib.parse.urlparse(url)
        domain = parse.netloc.split('.')
        try:
            int(domain[-1],0) 
            return 3
        except ValueError:
            return 0


    def Scan_Symbol(url): # URL에서 @가 존재할시 피싱 점수 부여
        if '@' in url:
            return 2
        else:
            return 0

    def Scan_Double_Slash(url): # URL에서 //가 존재할시 피싱 점수 부여
        parse = urllib.parse.urlparse(url)
        path = parse.path
        if '//' in path:
            return 2
        else:
            return 0
    
    def Scan_Sub_Domain(url): #서브 도메인의 개수를 통해 피싱 사이트 점수 부여
        from tld import get_tld
        url = ScanPhishing.remove_www(url)
        IP_score = ScanPhishing.having_IP_Address(url)
        if IP_score == 3:
            return 3
        domain = get_tld(url, as_object=True)
        if domain.subdomain == "":
            return 0
        dot = domain.subdomain.count('.')
        if dot == 0:
            return 1
        else: 
            return 2

    def URL_bar(url):
        if '-' in url:
            return 1
        else:
            return 0

    def URL_Length(url):
        if len(url) < 54:
            return 0
        elif len(url) >= 54 and len(url) <= 75:
            return 1
        else:
            return 2

    def remove_www(url):
        if "www." in url[:12]:
            url = url.replace("www.","")
        return url

    def Scan_SSL(url):
        #if 'http://' in url:
        #    return 2
        import trust_issuer_list
        from urllib.parse import urlparse
        try:
            url = urlparse(url)
            url = url.hostname
            try:
                s = ScanPhishing.https_connect(url)
                if s == 1:
                    return 2
            except TimeoutError:
                return 0
            cert = s.getpeercert()
            issuer = dict(x[0] for x in cert['issuer'])
            issuer_by = issuer['organizationName']
            #print(issuer_by)
            trusted_issuer_list = trust_issuer_list.TRUST_LIST #리스트화 시킨 인증기관
            for trusted_issuer in trusted_issuer_list:
                if trusted_issuer == issuer_by:
                    return -1
            else:
                return 2
                

            notAfter = cert['notAfter']
            notBefore = cert['notBefore']
            init_date = parse(notBefore)
            expiration_date = parse(notAfter)
            total_days = (expiration_date.date() - init_date.date()).days
            if total_days >= 365:
                return 0
            else:
                return 1
        except:
            print("URL Miss")
            pass

    def reg_domain(url):
        try:
            total_date = ScanPhishing.reg_date(url)
            #print(total_date)
            if total_date > 365:
                return -1
            else:
                return 2
        except:
            return 3
    
    def reg_date(url):
        from datetime import datetime, timedelta
        domain = whois.whois(url)
        #print(domain)
        #print(type(domain.creation_date))
        if type(domain.creation_date) is list:
            creation_date = domain.creation_date[0]
        else:
            creation_date = domain.creation_date
        
        if type(domain.updated_date) is list:
            updated_date = domain.updated_date[0]
        else:
            updated_date = domain.updated_date
        
        total_date = (updated_date - creation_date)
        total_date2 = total_date.days
        #print(total_date2)
        return total_date2


    
    def https_connect(url):
        try:
            host = (url,443)
            ctx = ssl.create_default_context()
            s = ctx.wrap_socket(socket.socket(),server_hostname= url)
            s.connect(host)
            return s
        except:
            return 1
            
    
    def unshort_url(url):
        try:
            unshortener = UnshortenIt()
            url1 = unshortener.unshorten(url)
            return url1
        except:
            return url

    def Scan_Main(url):
        if 'http' not in url:
            url = 'http://' + url 
        uri = ScanPhishing.unshort_url(url)
        score1 = ScanPhishing.having_IP_Address(uri) # URL에서 IP 문자열이 존재하는지 체크
        score2 = ScanPhishing.Scan_Symbol(uri) # URL에서 @ 문자열 체크
        score3 = ScanPhishing.Scan_Double_Slash(uri) #URL 문자열 7 이후 //가 존재하는 체크
        score4 = ScanPhishing.Scan_Sub_Domain(uri) #Sub 도메인 갯수 체크
        score5 = ScanPhishing.Scan_SSL(uri) #웹페이지 인증서 SSL 검사
        score6 = ScanPhishing.URL_bar(uri) # URL 에서 - 문자열이 존재하는지 여부 체크
        score7 = ScanPhishing.URL_Length(uri) # URL 길이 54 이상인지 체크
        score8 = ScanPhishing.reg_domain(uri) # 도메인 등록일 체크
        score = score1 + score2 + score3 + score4 + score5 + score6 + score7 + score8
        return score
    
    
